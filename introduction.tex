\section{Introduction}
The immense success of deep learning networks depends upon the availability of well-annotated training datasets on the domains of the tasks of interest. 
%Deep learning networks have shown significant advancement in the field of computer vision with image classification\cite{imagenet} as one of the prominent examples. A key factor to achieve such advancements is the availability of well-annotated training datasets on the domains of the tasks of interest. 
However, such annotations can be overly expensive to attain for the amount of data required for plausible performance by todayâ€™s deep neural networks. 
Domain adaptation approaches attempt to compensate for lack of annotated data in a \textit{target domain}, by leveraging information from a \textit{source domain}, for which annotated data is easier to obtain. 
Domain adaptation (DA) aims to learn domain invariant features which are discriminative in nature, so that task classifiers learned from the source data can be readily applied to the target domain~\cite{uda,dann,ctc,ltdan,atda,saito2017maximum}.
Existing unsupervised DA (UDA) approaches assume that the source domain has clean labeled data training data, while the target data is unlabeled. 
This is a restrictive assumption, since source domain data is usually collected from crowd sourcing platform or crawling through the Internet making their labels noisy and not completely reliable.

In this work, we address the more realistic and significantly more challenging wildy unsupervised domain adaptation (WUDA) [][], which aims to transfer knowledge from noisy labeled data in source domain ($\tilde{P_s}$, i.e., noisy source data) to unlabeled target data ($P_{x_{t}}$).
This is a relatively unexplored area and it is only recently that researchers have started to address this problem[].
%Unfortunately, existing DA methods share an implicit assumption that there are no noisy source data. Namely, these methods focus on transferring knowledge from clean source data ($P_s$) to unlabeled target data ($P_{x_{t}}$).\\
A naive approach to handle WUDA is to directly apply standard UDA methods, which will simply match the target domain with the entire noisy
source domain, resulting in severe negative transfer and performance degradation. 

In this work, we propose a novel approach to address the WUDA task, which aims to select clean instances from the noisy source samples and use these samples to update the domain adaptation model. 
The bottleneck is how to select the clean instances out of noisy instances?
Inspired by the success of the small-loss clean sample selection approaches, we incorporate one of the state-of-the-art model \textit{Co-teaching}\cite{coteaching} in \textit{domain-adversarial neural network} (DANN)\cite{dann}. 
Co-teaching addresses the task of image classification under noisy labels, is based on the study that deep models can memorize easy instances first, and gradually adapt to hard instances as training epochs become large~\cite{memorization}. 
It trains two networks in parallel and updates the weights of the networks using only the small loss samples and the gradients of the two networks are switched during the parameter update. 
Our proposed method worked as a plug in for standard adversarial domain adaptation methods.
As in standard adversarial DA, there are mainly two losses: classification loss (to learn the discriminative features), domain loss (to learn the domain invariant features). and there are three networks $G_f$ ( feature extractor), $G_d$ (domain discriminator), $G_y$ (classifier). In our proposed method for WUDA, two identical feature extractors are maintained $G_{f}^1$, $G_{f}^2$. Classification loss is calculated only through small loss instances and cross propagated in the peer feature extractor network to update the parameters. However, domain loss is backpropagated as in standard DA using only one feature extractor; say $G_{f_{1}}$.

Extensive experiments and comparisons with the state-of-the-art approaches have been performed on three different datasets, namely Office 31[], Office Home[] with both -- and --- noise labels.
Further, experiments on the Bing Caltech 256 dataset shows the effectiveness of the approach for real noisy data. 


\section{Related Work}
