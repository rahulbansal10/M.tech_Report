\section{Introduction}
Deep learning networks have shown significant advancement in the field of computer vision with image classification\cite{imagenet} as one of the prominent examples. A key factor to achieve such advancements is the availability of well-annotated training datasets on the domains of the tasks of interest. However, such annotations can be overly expensive to attain for the amount of data required for plausible performance by todayâ€™s deep neural networks. Domain adaptation approaches attempt to compensate for lack of annotated data in a \textit{target domain}, by leveraging information from a \textit{source domain}, for which annotated data is easier to obtain. Domain adaptation (DA) aims to learn domain invariant features which are discriminative in nature,  so that task classifiers learned from the source data can be readily applied to the target domain\cite{uda,dann,ctc,ltdan,atda,saito2017maximum}.\\

Existing domain adaptation (DA) methods train with clean labeled data in source domain (i.e., clean source data) and unlabeled data in target domain (i.e., unlabeled target data) to obtain classifiers for the target domain. However, this is an ideal scenario. But usually source domain data is collected from crowd sourcing platform or crawl from Internet or social media and the labels of source domain data are not very much reliable.\\
Motivated by this, it brings us a new, more realistic and more challenging problem, wildy unsupervised domain adaptation (WUDA). This adaptation aims to transfer knowledge
from noisy labeled data in source domain ($\tilde{P_s}$, i.e., noisy source data) to unlabeled target data ($P_{x_{t}}$).
Unfortunately, existing DA methods share an implicit assumption that there are no noisy source data. Namely, these methods focus on transferring knowledge from clean source data ($P_s$) to unlabeled target data ($P_{x_{t}}$).\\

The most naive approach to handle WUDA is to directly apply standard DA methods to it, but standard DA methods will simply match the target domain with the entire noisy
source domain, resulting in severe negative transfer. The next best direction could be training on selected samples, if somehow clean instances can be selected out of noisy samples and use those samples to update the model. The bottleneck is how to select the clean instances out of noisy instances ??\\
Going on the lines of selecting out clean instances, we incorporate one of the state of art model \textit{Coteaching}\cite{coteaching} in \textit{domain-adversarial neural network} (DANN)\cite{dann}. Coteaching: learning with noisy instances, is based on the study that deep models can memorize easy instances first, and gradually adapt to hard instances as training epochs become large\cite{memorization}. Co-teaching trains two networks in parallel and
updates the weights of the networks using only the small loss samples. In addition, the
gradients of the two networks are switched during the parameter update. Our proposed method worked as a plug in for standard adversarial domain adaptation methods.\\

As in standard adversarial DA, there are mainly two losses: classification loss (to learn the discriminative features), domain loss ( to learn the domain invariant features). and there are three networks $G_f$ ( feature extractor), $G_d$ (domain discriminator), $G_c$ (classifier). In our proposed method for WUDA, two identical feature extractors are maintained $G_{f_{1}}$, $G_{f_{2}}$. Classification loss is calculated only through small loss instances and cross propagated in the peer feature extractor network to update the parameters. However, domain loss is backpropagated as in standard DA using only one feature extractor; say $G_{f_{1}}$.