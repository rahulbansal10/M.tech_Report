\begin{abstract} 
Domain adaptation learns the task for unlabeled target domain data by knowledge transfer from a source domain with rich annotations. It is not uncommon that “source-domain engineering” becomes a cumbersome process in domain adaptation: the high-quality source domains highly related to the target domain are hardly available.  Here, we consider a new, more realistic and more challenging problem setting, where model has to be trained with noisy labeled data from source domain and unlabeled data from target data; named wild unsupervised domain adaptation(WUDA). Running standard domain adaptation netowork in WUDA setting results in severe negative transfer from noisy source domain. Co-teaching is one of the state of the art of the method in learning classifiers from noisy data. In this work, we incorporate co-teaching framework into standard domain adaptation network to train model using noisy source data and unlabeled target data. Here, we propose end to end deep neural architecture incorporating co-teaching framework in standard domain adaptation network. By extensive experiments, we show that our approach eliminates the negative transfer from noisy source data.
\end{abstract}